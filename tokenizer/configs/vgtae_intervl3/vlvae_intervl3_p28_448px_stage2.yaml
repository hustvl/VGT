experiment:
  project: VGTAE_intervl3
  name: vlvae_intervl3_p28_448px_stage2_GAN
  output_dir: checkpoints/vlvae_intervl3_p28_448px_stage2_GAN
  max_train_examples: 1_281_167
  save_every: 5_000
  eval_every: 5_000
  generate_every: 1_000
  log_every: 50
  log_grad_norm_every: 500
  resume: True
  init_weight: ""

model:
  name: VLVAE_InterVL3_Train
  stage1_ckpt: "./checkpoints/VGTAE_intervl3_stage1/checkpoint-100000/unwrapped_model/pytorch_model.bin"
  mllm_path: "OpenGVLab/InternVL3-1B"
  dc_ae_path: "mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers"
  embed_dim: 32
  encoder_norm: True
  kl: True
  max_noise_strength: 0.1
  scale_embeding: 1.0

losses:
  name: VGTAE_ReconstructionLoss
  discriminator_start: 30000
  quantizer_weight: 1.0
  discriminator_factor: 1.0
  discriminator_weight: 0.1
  perceptual_loss: lpips-convnext_s-1.0-0.1
  perceptual_weight: 1.1
  distill_weight: 1.0
  reconstruction_loss: "l1"
  reconstruction_weight: 1.0
  lecam_regularization_weight: 0.001
  kl_weight: 1e-6
  logvar_init: 0.0

dataset:
  params:
    train_shards_path_or_url: "datacomp_sharded/train/datacomp-train-{000000..140089}.tar"
    eval_shards_path_or_url: "imagenet_sharded/val/imagenet-val-{0000..0009}.tar"
    num_workers_per_gpu: 12
  preprocessing:
    resize_shorter_edge: 448
    crop_size: 448
    random_crop: True
    random_flip: True
    normalize_mean: [0.5, 0.5, 0.5]
    normalize_std: [0.5, 0.5, 0.5]
    imagenet_norm: True

optimizer:
  name: adamw 
  params:
    learning_rate: 1e-4
    discriminator_learning_rate: 1e-4
    beta1: 0.9
    beta2: 0.95
    weight_decay: 1e-4
  encoder_lr_muti: 0.1

lr_scheduler:
  scheduler: cosine
  params:
    learning_rate: ${optimizer.params.learning_rate}
    warmup_steps: 3000
    end_lr: 1e-4


training:
  ddp_find_unused_parameters: True
  gradient_accumulation_steps: 1
  per_gpu_batch_size: 16
  mixed_precision: bf16
  enable_tf32: True
  enable_wandb: True
  wandb_api_key: xxxxxxxxxxxx
  use_ema: False
  seed: 42
  max_train_steps: 80000
  num_generated_images: 8
  max_grad_norm: 1.0