
# ImageNet1K-T2I-QwenVL-FLUX

This dataset is from [csuhan/ImageNet1K-T2I-QwenVL-FLUX](https://huggingface.co/datasets/csuhan/ImageNet1K-T2I-QwenVL-FLUX).
It contains ImageNet1K images with detailed captions generated by QwenVL for FLUX training.

## Download

Download the dataset by:
```shell
cd /path/to/VGT
huggingface-cli download csuhan/ImageNet1K-T2I-QwenVL-FLUX --local-dir data/imagenet1k-t2i/raw --repo-type dataset
```

```text
VGT/
├── data
    ├── imagenet1k-t2i
        ├── raw
            ├── 00000.parquet
            ├── 00001.parquet
            ├── ...
        ├── images
        ├── data.json
```

## Extract Images from Parquet

The images are stored as base64-encoded bytes in the parquet files. We need to extract them:

```shell
cd data/imagenet1k-t2i
vim extract.py
```

Write the following into extract.py:

```python
import multiprocessing as mp
import argparse
import os
from tqdm import tqdm
from glob import glob
import pandas as pd
import base64
from io import BytesIO
from PIL import Image


def process_parquet(parquet_file, output_dir):
    """Process a single parquet file and extract images"""
    df = pd.read_parquet(parquet_file)
    data_list = []
    
    for idx, row in tqdm(df.iterrows(), total=len(df), desc=f"Processing {os.path.basename(parquet_file)}"):
        # Extract image bytes
        image_bytes = row['image']['bytes']
        
        # Decode base64 if needed
        if isinstance(image_bytes, str):
            image_bytes = base64.b64decode(image_bytes)
        
        # Save image
        image = Image.open(BytesIO(image_bytes))
        parquet_name = os.path.basename(parquet_file).replace('.parquet', '')
        image_filename = f"{parquet_name}_{idx:06d}.png"
        image_path = os.path.join(output_dir, image_filename)
        image.save(image_path)
        
        # Extract caption from conversations
        caption = ""
        for conv in row['conversations']:
            if conv['from'] == 'human':
                caption = conv['value']
                break
        
        # Store metadata
        data_list.append({
            'image': f"images/{image_filename}",
            'caption': caption
        })
    
    return data_list


def single_process(parquet_list, output_dir):
    all_data = []
    for parquet_file in parquet_list:
        data = process_parquet(parquet_file, output_dir)
        all_data.extend(data)
    return all_data


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--start', default=0, type=int)
    parser.add_argument('--end', default=-1, type=int)
    parser.add_argument('--num-processes', default=8, type=int)
    args = parser.parse_args()

    # Create output directory
    output_dir = 'images'
    os.makedirs(output_dir, exist_ok=True)

    # Get all parquet files
    parquet_files = sorted(glob('raw/*.parquet'))
    
    if args.end == -1:
        args.end = len(parquet_files)

    parquet_files = parquet_files[args.start:args.end]

    num_files = len(parquet_files)
    num_processes = args.num_processes
    num_files_per_process = num_files // num_processes
    res = num_files % num_processes
    if res > 0:
        num_processes += 1

    # Use multiprocessing
    with mp.Pool(num_processes) as pool:
        results = []
        for process_id in range(num_processes):
            start_idx = process_id * num_files_per_process
            if process_id < num_processes - 1:
                end_idx = (process_id + 1) * num_files_per_process
            else:
                end_idx = len(parquet_files)
            
            result = pool.apply_async(single_process, 
                                     args=(parquet_files[start_idx:end_idx], output_dir))
            results.append(result)
        
        # Collect all results
        all_data = []
        for result in results:
            all_data.extend(result.get())
    
    # Save data.json
    import json
    with open('data.json', 'w') as f:
        json.dump(all_data, f, indent=2)
    
    print(f"Extracted {len(all_data)} images to {output_dir}")

```

Then run the python file to extract all images:

```shell
python extract.py --num-processes 8
```

## Set config

```python
from src.datasets.text2image.caption_datasets import CaptionDataset
from mmengine.config import read_base
from mmengine.dataset import InfiniteSampler
from xtuner.dataset import ConcatDataset

with read_base():
    from .processors import prompt_template, tokenizer, image_size, pad_index

max_length = 128

dataset = dict(type=CaptionDataset,
               image_size=image_size,
               cap_source='caption',
               data_path='data/imagenet1k-t2i/data.json',
               cap_folder='data/imagenet1k-t2i',
               image_folder='data/imagenet1k-t2i',
               unconditional=0.1,
               prompt_template=prompt_template,
               ceph_folder=None,
               ceph_config=None,
               tokenizer=tokenizer,
               max_length=max_length)
```
