
# ShareGPT-4o-Image

This dataset is from [FreedomIntelligence/ShareGPT-4o-Image](https://huggingface.co/datasets/FreedomIntelligence/ShareGPT-4o-Image).
It contains high-quality text-to-image pairs generated by GPT-4o.

## Download

Download the dataset by:
```shell
cd /path/to/VGT
huggingface-cli download FreedomIntelligence/ShareGPT-4o-Image --local-dir data/sharegpt-4o-image/raw --repo-type dataset
```

```text
VGT/
├── data
    ├── sharegpt-4o-image
        ├── raw
            ├── text_to_image.json
            ├── text_to_image_part_0.tar
            ├── text_to_image_part_1.tar
            ├── ...
            ├── text_to_image_part_9.tar
        ├── images
        ├── data.json
```

## Extract Images from Tar Files

The images are stored in tar files (part_0 to part_9). We need to extract them:

```shell
cd data/sharegpt-4o-image/raw
vim extract.py
```

Write the following into extract.py:

```python
import multiprocessing as mp
import argparse
import os
from tqdm import tqdm
from glob import glob
import subprocess


def single_process(tar_list, output_dir):
    for tar_file in tqdm(tar_list):
        # Extract tar files directly to output directory
        subprocess.run(["tar", "-xf", tar_file, "-C", output_dir, "--no-same-owner"])


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--num-processes', default=8, type=int)
    args = parser.parse_args()

    # Create output directory
    output_dir = '../images'
    os.makedirs(output_dir, exist_ok=True)

    # Find all tar files
    tar_files = sorted(glob('text_to_image_part_*.tar'))
    
    print(f"Found {len(tar_files)} tar files to extract")

    num_tars = len(tar_files)
    num_processes = min(args.num_processes, num_tars)
    num_tars_per_process = num_tars // num_processes
    res = num_tars % num_processes
    if res > 0:
        num_processes += 1

    processes = [mp.Process(target=single_process,
                            args=(tar_files[process_id * num_tars_per_process:
                                            (process_id + 1) * num_tars_per_process]
                                  if process_id < num_processes - 1
                                  else tar_files[process_id * num_tars_per_process:],
                                  output_dir))
                 for process_id in range(num_processes)]

    # Run processes
    for p in processes:
        p.start()

    # Exit the completed processes
    for p in processes:
        p.join()
    
    print(f"Extraction completed. Images saved to {output_dir}")

```

Then run the python file to extract all tar files:

```shell
python extract.py --num-processes 8
```

## Process JSON Metadata

After extracting images, we need to process the JSON file to create data.json:

```shell
cd data/sharegpt-4o-image
vim process_metadata.py
```

Write the following into process_metadata.py:

```python
import json
from tqdm import tqdm
import os


def process_json_file():
    """Process text_to_image.json and create data.json"""
    json_file = 'raw/text_to_image.json'
    
    print(f"Processing {json_file}...")
    
    with open(json_file, 'r', encoding='utf-8') as f:
        data_list = json.load(f)
    
    all_data = []
    missing_count = 0
    
    for item in tqdm(data_list, desc="Processing entries"):
        input_prompt = item.get('input_prompt', '')
        output_image = item.get('output_image', '')
        resolution = item.get('output_image_resolution', [])
        
        if output_image and input_prompt:
            # Extract filename from path
            # e.g., "image/17413.png" -> "image/17413.png"
            image_path = f"images/{os.path.basename(output_image)}"
            
            # Check if image exists
            if os.path.exists(image_path):
                data_entry = {
                    'image': image_path,
                    'caption': input_prompt
                }
                
                # Add resolution if available
                if resolution and len(resolution) == 2:
                    data_entry['width'] = int(resolution[0])
                    data_entry['height'] = int(resolution[1])
                
                all_data.append(data_entry)
            else:
                missing_count += 1
    
    # Save data.json
    with open('data.json', 'w', encoding='utf-8') as f:
        json.dump(all_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nProcessed {len(all_data)} image-caption pairs")
    if missing_count > 0:
        print(f"Warning: {missing_count} images not found")
    print(f"Saved to data.json")


if __name__ == '__main__':
    process_json_file()

```

Then run the python file:

```shell
python process_metadata.py
```

## Set config

```python
from src.datasets.text2image.caption_datasets import CaptionDataset
from mmengine.config import read_base
from mmengine.dataset import InfiniteSampler
from xtuner.dataset import ConcatDataset

with read_base():
    from .processors import prompt_template, tokenizer, image_size, pad_index

max_length = 128

dataset = dict(type=CaptionDataset,
               image_size=image_size,
               cap_source='caption',
               data_path='data/sharegpt-4o-image/data.json',
               cap_folder='data/sharegpt-4o-image',
               image_folder='data/sharegpt-4o-image',
               unconditional=0.1,
               prompt_template=prompt_template,
               ceph_folder=None,
               ceph_config=None,
               tokenizer=tokenizer,
               max_length=max_length)
```
